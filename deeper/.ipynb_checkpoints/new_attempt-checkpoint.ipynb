{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ha-ha classics\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import os \n",
    "\n",
    "# sklearn\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve\n",
    "\n",
    "# 2nd category\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from lightgbm import LGBMClassifier as lgbm\n",
    "\n",
    "# 3rd category\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# misc\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train_values (1).csv')\n",
    "labels = pd.read_csv('data/train_labels (1).csv')\n",
    "test = pd.read_csv('data/test_values (1).csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_ids = train.columns[0]\n",
    "geo_levels = train.columns[1:4]\n",
    "numeric = train.columns[4:8]\n",
    "categorical = list(train.columns[8:15])\n",
    "categorical.append(train.columns[26])\n",
    "flags = train.columns[15:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fe(dataset):\n",
    "    '''\n",
    "    dataset - supposed to be train or test pd.DataFrames\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    dataset['height_area_ratio'] = dataset['height_percentage']/dataset['area_percentage']\n",
    "    dataset['is_old'] = dataset['age']>10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-means clustering for geolevels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_cols = ['cluster_' + str(i) for i in range(17)]\n",
    "print(enc_cols)\n",
    "\n",
    "def append_clusters_to_dataset(main_set, clustering):\n",
    "    enc = OneHotEncoder()\n",
    "    ohe = enc.fit_transform(clustering.reshape(-1,1))\n",
    "    ohe = ohe.toarray()\n",
    "    add_on = pd.DataFrame(ohe,columns = enc_cols)\n",
    "    \n",
    "    X = pd.concat([main_set,add_on],axis = 1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def create_clustering_data(dataset): #instance of np.ndarray\n",
    "    subdata = dataset[:,1:4].copy()\n",
    "    return subdata\n",
    "\n",
    "def perform_clustering(subdata,col_weights = [100,10,1]):\n",
    "    for i in range(len(col_weights)):\n",
    "        subdata[:,i] *= col_weights[i]\n",
    "        \n",
    "    #print(subdata.shape)\n",
    "    print('...clustering in process...')\n",
    "    clustering = KMeans(17).fit(subdata)\n",
    "    print('...clustering done.')\n",
    "    #print(clustering.labels_.shape)\n",
    "    print('cluseering done!')\n",
    "    \n",
    "    return clustering.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train = create_clustering_data(np.array(train))\n",
    "clustering_train = perform_clustering(sub_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = append_clusters_to_dataset(train, clustering_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_test = create_clustering_data(np.array(test))\n",
    "clustering_test = perform_clustering(sub_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = append_clusters_to_dataset(test, clustering_test)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### StandartScaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = StandardScaler()\n",
    "\n",
    "train[numeric] = enc.fit_transform(train[numeric])\n",
    "test[numeric] = enc.fit_transform(test[numeric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ohe(data,categorical):\n",
    "    \n",
    "    enc = OneHotEncoder()\n",
    "    one_hot = enc.fit_transform(data[categorical]).toarray()\n",
    "    #print(one_hot.shape)\n",
    "    \n",
    "    cols = categorical\n",
    "    #print(cols)\n",
    "    \n",
    "    cats = enc.categories_\n",
    "    #print(cats[0])\n",
    "\n",
    "    new_column_names = []\n",
    "    for k in range(len(cols)):\n",
    "        for levels in range(len(cats[k])):\n",
    "            #print()\n",
    "            new_column_names.append(cols[k] + '_' + cats[k][levels])\n",
    "            \n",
    "    #print(new_column_names)     \n",
    "    \n",
    "    categorical_dataframe = pd.DataFrame(one_hot, columns = new_column_names)\n",
    "    new_dataset = pd.concat([data.drop(categorical,axis = 1),categorical_dataframe],axis = 1)\n",
    "    return new_dataset\n",
    "\n",
    "train = ohe(train,categorical)\n",
    "test = ohe(test,categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_geo(dataset):\n",
    "    for cols in dataset.columns:\n",
    "        if 'geo' in cols:\n",
    "            dataset.drop(cols,inplace = True,axis = 1)\n",
    "drop_geo(train)\n",
    "drop_geo(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_ids = test['building_id'].copy()\n",
    "train.drop('building_id',axis = 1,inplace = True)\n",
    "test.drop('building_id',axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.array(train)\n",
    "test = np.array(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(labels['damage_grade']).ravel()\n",
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(train,\n",
    "                                                 y,\n",
    "                                                 random_state = 1003,\n",
    "                                                test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:06] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 458 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:06] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 426 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:06] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 416 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:06] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 430 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:08] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 448 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:08] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 454 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:08] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 444 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:08] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 434 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:11] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 438 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:11] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 420 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:11] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 408 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:11] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 420 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[0]\tvalidation_0-mlogloss:0.97146\n",
      "Will train until validation_0-mlogloss hasn't improved in 20 rounds.\n",
      "[01:58:13] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 420 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:13] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 418 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:13] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 428 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:13] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 430 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:15] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 458 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:15] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 446 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:15] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 460 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:15] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 446 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:16] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 412 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:16] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 418 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:16] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 404 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:16] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 420 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:20] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 420 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:20] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 414 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:20] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 434 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:20] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 418 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:22] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 358 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:22] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 354 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:22] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 380 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:22] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 346 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:23] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 422 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:23] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 420 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:23] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 408 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:23] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 408 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[2]\tvalidation_0-mlogloss:0.85887\n",
      "[01:58:28] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 428 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:28] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 406 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:28] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 410 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:28] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 412 extra nodes, 0 pruned nodes, max_depth=8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m_ctypes/callbacks.c\u001b[0m in \u001b[0;36m'calling callback function'\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda_\\envs\\venv\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_log_callback\u001b[1;34m(msg)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0m_log_callback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m     \u001b[1;34m\"\"\"Redirect logs from native library into Python console\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0:s}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:30] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 376 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:30] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 404 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:30] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 402 extra nodes, 0 pruned nodes, max_depth=8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m_ctypes/callbacks.c\u001b[0m in \u001b[0;36m'calling callback function'\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda_\\envs\\venv\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_log_callback\u001b[1;34m(msg)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0m_log_callback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m     \u001b[1;34m\"\"\"Redirect logs from native library into Python console\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0:s}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:31] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 404 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:31] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 408 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:31] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 402 extra nodes, 0 pruned nodes, max_depth=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:33] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 416 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:33] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 400 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:33] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 390 extra nodes, 0 pruned nodes, max_depth=8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m_ctypes/callbacks.c\u001b[0m in \u001b[0;36m'calling callback function'\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda_\\envs\\venv\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_log_callback\u001b[1;34m(msg)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0m_log_callback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m     \u001b[1;34m\"\"\"Redirect logs from native library into Python console\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0:s}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:38] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 346 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:38] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 358 extra nodes, 0 pruned nodes, max_depth=8\n",
      "[01:58:38] INFO: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\tree\\updater_prune.cc:101: tree pruning end, 400 extra nodes, 0 pruned nodes, max_depth=8\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(n_estimators = 100,\n",
    "                    max_depth = 8,\n",
    "                    learning_rate = 0.4,\n",
    "                    verbosity = 2,\n",
    "                    booster = 'gbtree',\n",
    "                    n_jobs = 4,\n",
    "                    subsample = 0.8,\n",
    "                    num_parallel_tree=4\n",
    "                    )\n",
    "\n",
    "xgb.fit(X_train,\n",
    "        y_train,\n",
    "        early_stopping_rounds=20,\n",
    "        verbose = 2,\n",
    "        eval_set = [(X_test, y_test)],\n",
    "        eval_metric = \"mlogloss\"\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.6332764144970358\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print('f1: {}'.format(f1_score(y_pred,y_test,average='micro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outputting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all_pred = xgb.predict(np.array(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86868,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_ids = X_check['building_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(y_all_pred,building_ids):\n",
    "\n",
    "    building_ids = np.array(X_check['building_id'])\n",
    "    preds = y_all_pred\n",
    "    sub = pd.DataFrame()\n",
    "    sub['building_id'] = building_ids\n",
    "    sub['damage_grade'] = y_all_pred\n",
    "    sub.set_index('building_id',inplace = True)\n",
    "    print(sub.shape)\n",
    "    sub.to_csv('submissions/sub_xgb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86868, 1)\n"
     ]
    }
   ],
   "source": [
    "create_submission(y_all_pred,building_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
